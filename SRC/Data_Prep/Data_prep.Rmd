# Cleaning the Data
So after retrieving and mergig our data directly form the IMBD site, we now need to chcek and clean the data. In this markdown the data set is cleaned, reformatted and restructured.

```{r libraries, message=FALSE, warning=FALSE}
install(tidyverse)
library(tidyverse)
```

```{r reformatting the data, message=FALSE, warning=FALSE}
movie_data <- read_csv(movie_data)

movie_data <- movie_data %>%
  mutate(across(c(tconst, directors, writers, titleType, isAdult,genres, parentTconst,region,language,isOriginalTitle), as.factor)) %>%
  mutate(across(c(averageRating,numVotes,runtimeMinutes, title,seasonNumber, episodeNumber), as.numeric)) %>%
  mutate(across(c(primaryTitle, originalTitle,types, attributes),as.string))
```


First, let's think about some operalization basics. Or more specifically, the operalization of our variables.

# starting with out DV: ratings
```{r Raw DV print}
print(summary(movie_data$averageRating))
```

Okay. So the scale is okay BUT remember that these are AVERAGE ratings, and that on average ratings 1 and 10 are quite extreem and frankly, unrealistic.

let's visualize how ratings are distributed

```{r DV plots, message=FALSE, warning=FALSE}
ggplot((movie_data), aes(x = averageRating)) +
  geom_histogram(binwidth = 1, fill = "darkorange", color = "black") +
  labs(title = "Distribution of averageRating",
       x = "Average Rating",y = "Frequency") +
  scale_x_continuous(breaks = seq(0, 10, by = 1)) +  
  theme_minimal()
```

```{r}
ggplot(movie_data, aes(x = averageRating)) +
  geom_histogram(binwidth = 0.1, fill = "orange", color = "black") +
  scale_x_continuous(breaks = seq(0, 10, by = 0.5), limits = c(0, 10), labels = scales::number_format(accuracy = 0.1)) +
  labs(x = "averageRating", y = "Frequency") +
  theme_minimal()
```
As you can see there appears to be a normal distribution that is slightly skewed to the left.
If you think logically about this this may be a result from the number of reviews given as opposed to the actual rating

```{r DV vs NumVotes, message=FALSE, warning=FALSE}
print(summary(movie_data$numVotes))
```

Do you see how the average movie only has 106 votes? Or even 5! that will defiantely influence the average 

```{r Plot DV and numVotes, message=FALSE, warning=FALSE}
ggplot(movie_data, aes(x = numVotes)) +
  geom_dotplot(fill = "darkorange", color = "black", binwidth = 500) +
  labs(title = "Distribution of numVotes",
       x = "Number of Votes", y = "Frequency") + 
  theme_minimal()

movie_data$numVotes_group <- cut(movie_data$numVotes, breaks = c(-Inf, 50, Inf), labels = c("Below 50", "Above 50"))
print(table(movie_data$numVotes_group))
```` 

Okay, so let's filter some of there observations out. These observations are not deleted. But they are simply left behind in the corner. We want reliable data and these observation are unlikely to be reliable. But instead of arbritarily unselecting stuff we should plot the data and see where some issues lie. 

```{r Filtering DV, message=FALSE, warning=FALSE}

below_100 <- movie_data %>%
  select(numVotes) %>%
  filter(numVotes < 100)

ggplot(below_100, aes(x = numVotes)) +
  geom_histogram() +
  labs(title = "Distribution of numVotes Below 100",
       x = "Group (Interval of 10)", y = "Number of Votes") +
  theme_minimal()
```

So as you may have seen these observation are heavily left skewed. So we are indeed likely to get these extreme average rating value's from the observations that have very few number of ratings. 

Let's filter these observations out now. 

```{r}
movie_data <- movie_data %>%
  filter(numVotes > 100) 
```

# IV data_set

Now that we have clean

